<!DOCTYPE html>
<head>
  <meta charset="utf-8">
  <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet">  
  <link rel="stylesheet" type="text/css" href="spinner.css">
  <script src="keras.js"></script>
  <script src="three.min.js"></script>
  <script src="bundle.js"></script>
  <script src="imagenet.js"></script>

  <script type="x-shader/x-vertex" id="vertexshader">
    attribute float alpha;
    attribute vec3 color;
    attribute float size;
    varying float vAlpha;
    varying vec3 vColor;
    void main() {
      vAlpha = alpha;
      vColor = color;
      vec4 mvPosition = modelViewMatrix * vec4( position, 1.0 );
      gl_PointSize = size  * (500.0 / length(mvPosition.xyz));
      gl_Position = projectionMatrix * mvPosition;
    }
  </script>

  <script type="x-shader/x-fragment" id="fragmentshader">
    varying vec3 vColor;
    varying float vAlpha;
    void main() {
      if (vAlpha > 0.01) {
        gl_FragColor = vec4( vColor, vAlpha );
      } else {
        discard;
      }
    }
  </script>

  <style>
    body {
    font-family: 'Lato', sans-serif;
    margin: 0px 0px;
    }

    #content {
    margin: 80px 140px 40px 140px;
    }
    
    #input-canvas {
      background: #eeeeee;
      float:left;
    }
    
    #container {
      float:left;
      margin-left: 15px;
      margin-bottom: 20px;
      width:300px;
      height:300px;
    }

    #vis-container{
    position: relative;
    margin: 0px 70px;
    height: 100vh;
    }
    #vis {
    position: absolute;
    background-color: black;
    width: 100%;
    height: 100vh;
    }
    #predictions {
      display: none;
      position: absolute;
      text-align: right;
      color: #777777;
      right: 15px;
      top: 15px;
    }

    .bar {
    height: 8px;
    margin-right: 0px;
    margin-left: auto;
    margin-top: 10px
    margin-bottom: 10px;
    -webkit-transition: width 0.2s ease-out;
        transition: width 0.2s ease-out;
    }

    p {
    max-width:800px;
    }
    .text {
    float: left;
    width: 450px;
    padding-right: 80px;
    }
    #source {
    float: left;
    }
  </style>
</head>
<body>
  <div id="content">
    <h2>SCANNING AN ARTIFICIAL BRAIN</h2>
    <div class="text">
      <p>As the name implies, artificial neural networks are based on a simplified model of how we think our brains work. Real brains are made out of physical, interconnected cells called neurons whereas neural networks are made out of 'artificial' neurons - mathematical representations instead of the messy stuff in your head. Artificial neurons are arranged in interconnected layers, hence the 'deep' in deep learning. </p>

      <img src="https://upload.wikimedia.org/wikipedia/en/d/d1/FMRIscan.jpg" style="float:left; margin-right:10px;"/>
      
      <p>I've taken the neural net -> brain metaphor a bit further by making an 'MRI scan' for a popular image classifier network. A real MRI scan detects activity in the brain when the subject is stimulated, so you may see a different pattern of activity in the scan when the subject sees a scary spider vs a baby seal. When a neural network looks at an image, different regions of artificial neurons become 'activated'. </p>
      
        <p>For this visualization we feed Google's <a href src="https://research.googleblog.com/2016/03/train-your-own-image-classifier-with.html">Inception V3</a> network images from the internet.   </p>

<!--      <p>Image data enters the leftmost layer (you can still make out the rough shape of the original image) and as the signal passes through the network, neurons get excited and light up. The last layer the system guesses what's in the image by highlighting a square. Each square represents one of a thousand categories like 'cat' or 'airplane.'</p>-->

      <p>Use the arrow keys on your keyboard to rotate / zoom in. Created using <a href="https://github.com/transcranial/keras-js">keras.js</a> and <a href="https://threejs.org/">three.js</a></p>
    </div>
    <div id="source">
      <p>
        SELECT AN IMAGE: &nbsp;<select id="image-urls"></select>&nbsp;
      </p>
      OR PASTE AN IMAGE URL <input id="image-input"></input> <button type="button" id="button">GO!</button><br/>

      <br/>
      <canvas id="input-canvas" width="299" height="299"></canvas>
    </div>
    <div style="clear: both;"></div>
    <div id="container">
      <div id="spinner">
        <svg class="circular" viewBox="25 25 50 50">
          <circle class="path" cx="50" cy="50" r="20" fill="none" stroke-width="3" stroke-miterlimit="10"/>
        </svg>
      </div>
    </div>  
  </div>
  <script src="image_urls.js"></script>
  <script src="vis.js"></script>
  <script src="index.js"></script>
  <div id="vis-container">
  <div id="vis">
  </div>
  <div id="predictions"></div>
  </div>
  <div class="text">
    <p>The way you teach neural nets and brains end up being pretty similar.</p>
      
      <p>Let's say you're reading a picture book to a toddler. You point at the cute animals and enthusiastically call out "Lamb!" "Dog!" or "Cat!" - if the child points at a cow and says "Pig!" you'd gently correct "No, that's a cow, not a pig." After many repetitions, the young brain will magically wire its neurons up to identify farm animals. </p>

      <p>Analagously, researchers show a network millions of labelled photographs, compressing years of human visual experience into a few hours. If the network claims an image labelled 'bed' is an airplane, instead of wiring up physical neurons it corrects itself by nudging mathematical parameters.</p>

</div>
</body>
